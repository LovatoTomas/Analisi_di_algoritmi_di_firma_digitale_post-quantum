\chapter{Conclusioni}

Nel capitolo precedente, attraverso grafici e considerazioni, sono stati evidenziati i punti di forza e gli aspetti da migliorare per ciascuno dei candidati. In generale, tutte e tre si sono dimostrate ottime soluzioni poiché offrono elevate prestazioni e sono mature dal punto di vista della sicurezza, almeno per quanto riguarda le conoscenze attuali.

Il NIST ha indicato che i sistemi più adatti per essere standardizzati e sostituire quelli attuali sono i \textit{Lattice Based}. CRYSTALS Dilithium e FALCON offrono dimensioni delle chiavi e delle firme in linea con i sistemi attuali, oltre a tempi di esecuzione molto rapidi \cite{NISTthirdReport}.

Tra i due, il NIST mostra una preferenza per CRYSTALS Dilithium poiché, come rilevato da altre fonti e dai test sulle prestazioni, sembra essere meno vulnerabile agli attacchi \textit{side channel}, diventati oggetto di numerosi studi negli ultimi anni. Inoltre, CRYSTALS Dilithium è considerato più \textit{semplice}: a differenza di FALCON, CRYSTALS Dilithium non utilizza i calcoli in virgola mobile nel suo \textit{core}. Queste operazioni, oltre ad essere più onerose in termini di risorse, introducono un livello di imprecisione che, negli hardware più limitati, possono portare a fallimenti involontari nelle operazioni di firma e verifica \cite{NISTthirdReport}. D'altra parte, FALCON si distingue per la riduzione della dimensione dei messaggi, un aspetto importante quando si tratta di trasmissione di comunicazioni tramite le reti internet.

Per l'insieme di questi aspetti, sono di recente pubblicazione i primi standard del NIST per alcuni algoritmi di crittografia e altri di firma digitale a chiave asimmetrica: tra questi ci sono CRYSTALS Dilithium e SPHINCS+. FALCON necessiterà di maggiore tempo per la standardizzazione \cite{nist2024article}.

È importante sottolineare che, al termine del secondo \textit{round}, SPHINCS+ era considerato tra i finalisti alternativi per la firma digitale. Il suo successo, che lo ha portato a diventare uno degli algoritmi in fase di standardizzazione, è dovuto a due motivazioni principali: 
\begin{enumerate}
    \item Il NIST ha espresso la volontà di standardizzare algoritmi di firma digitale basati su problemi e teorie quanto più diverse possibile.
    \item Altri algoritmi candidati finalisti hanno subito delle rivalutazioni di sicurezza, tra cui \textit{Rainbow} \cite{rainbow-website}.
\end{enumerate}

Il primo punto è fondamentale: se il NIST decidesse di proseguire solo con algoritmi \textit{Lattice Based}, esisterebbe il rischio che in futuro venga individuata una vulnerabilità comune a tutti questi sistemi, compromettendo tutte le comunicazioni basate su tali tecnologie.

La scelta di includere anche SPHINCS+ tra i finalisti del terzo \textit{round} porta quindi ad una maggiore diversificazione e sicurezza nelle future comunicazioni, dato che si tratta di un algoritmo \textit{Hash Based}.

Per questo motivo il \textit{NIST Post-Quantum Cryptography Standardization Process} \cite{nist-pqc} non si fermerà al terzo \textit{round} ma proseguirà nella ricerca di altri algoritmi di firma digitale da standardizzare, ponendo maggiore attenzione agli algoritmi più unici, come quelli \textit{Isogeny Based} o \textit{Code Based}.

Un altro aspetto che il NIST cercherà nei futuri candidati è la capacità di operare anche a livelli di sicurezza più bassi. Attualmente, molte delle operazioni di crittografia e di firma digitale vengono eseguite con tecnologie che privilegiano l'efficienza in termini di tempi di esecuzione e risorse, come RSA 1024 o RSA 2048. Non tutti i settori sono pronti ad abbandonare le prestazioni offerte da questi sistemi per garantire una maggiore sicurezza.

Per proseguire con il processo di standardizzazione, il NIST è entrato in contatto diretto con i team di ricerca finalisti, al fine di sviluppare sistemi di firma digitale con un'interfaccia pubblica comune (API, \textit{Application Programming Interface}) il più compatibile possibile con i protocolli attuali. Tra gli obiettivi c'è anche la ricerca di più \textit{parameter sets} ottimizzati che permettano agli algoritmi di raggiungere i livelli di sicurezza più richiesti mantenendo prestazioni ottimali \cite{NISTthirdReport}.

\section{Altre metriche di performance e limitazioni}

I \textit{performance test} effettuati per questo progetto offrono una visione limitata, seppur sufficiente, delle caratteristiche da valutare per un algoritmo di firma digitale quantum resistant. Diversi aspetti non sono stati trattati per insufficienza di risorse, difficoltà tecniche o mancanza di fondamenti teorici.

I test di dimensione degli output (chiavi e firme) e dei tempi di esecuzione sono stati eseguiti in ambienti \textit{general purpose}, simili a quelli in cui questi sistemi verranno effettivamente utilizzati, ma utilizzando poca varietà di hardware. Tuttavia, gli stessi test hanno dimostrato che le proporzioni dei risultati restano consistenti su hardware differenti, permettendo di prevedere le prestazioni confrontandoli con quelli menzionati nella ricerca.

Tramite l'utilizzo di Windows Subsystem for Linux (WSL) è stato fissato ad un valore unico il tasso della frequenza di clock dell'ambiente Ubuntu, per rendere i tempi dei vari dispositivi maggiormente comparabili: il numero di istruzioni eseguite al secondo per l'ambiente virtualizzato era fisso. Purtroppo sono presenti fonti di errore imprevedibili dovute ad operazioni in background che, messe in esecuzione automaticamente nel sistema operativo primario o virtualizzato, possono aver influenzato i risultati finali. Per ridurre l'effetto di questa eventualità sono stati eseguiti più test ripetuti i cui risultati sono stati mediati.

Uno degli aspetti non considerati sono le esecuzioni su CPU con architettura ARM oppure su dispositivi di tipo IoT: in generale l'esecuzione di test su questi dispositivi risulta molto complessa poiché richiede una fase di compilazione ad hoc. Tuttavia, è proprio su questi dispositivi che è possibile individuare più facilmente alcune vulnerabilità ai \textit{side channel attacks}, come per FALCON, in cui è stata sfruttata l'analisi delle frequenze elettromagnetiche su Cortex-M4 \cite{falcon-sidechannel-attack}.

Una metrica rilevante per valutare ciascun candidato,  menzionata in alcuni report del NIST, è il tempo di trasmissione dell'output del processo di firma. Esso non è stato misurato direttamente nei \textit{performance test}, tuttavia l'analisi delle dimensioni delle chiavi e delle firme ha comunque permesso di sviluppare delle considerazioni. È evidente che, a parità di bitrate di trasmissione o ricezione, gli algoritmi con i tempi (o costi) di trasmissione inferiori sono quelli con l'output più compatto, come FALCON.

Infine, un ultimo aspetto non considerato nella ricerca ma individuabile nei report del NIST è l'utilizzo di memoria RAM (\textit{Random Access Memory}) e ROM (\textit{Read Only Memory}) necessaria ai vari algoritmi per il loro utilizzo. I test del NIST evidenziano che i migliori risultati sono raggiunti da CRYSTALS Dilithium, che può essere eseguito su sistemi con circa 9 KiB di RAM e 8 KiB di ROM. Questo tipo di analisi sono piuttosto rilevanti per comprendere in maniera semplice le compatibilità dei vari candidati con gli hardware più limitati \cite{NISTthirdReport}.

Le tecnologie che fanno affidamento ad hardware \textit{special purpose} o IoT sono molto diffuse, quindi, per la standardizzazione di FALCON e SPHINCS+, è necessario trovare modi per ridurre le risorse richieste, mantenendo comunque l'operatività delle funzioni.

\section{Il futuro processo di migrazione}

Nel contesto della crittografia post-quantum (PQC), è fondamentale prendere misure preventive per proteggere i dati che richiedono una sicurezza a lungo termine. Tali dati devono essere messi al sicuro fin da ora per evitare la minaccia degli attacchi di \textit{Retrospective Decryption}, nei quali un avversario può raccogliere informazioni crittografate oggi per decrittarle in futuro utilizzando computer quantistici. Sono due i principali approcci per garantire la sicurezza: il primo consiste nell'implementare sistemi ibridi che combinano tecnologie crittografiche pre-quantum con schemi post-quantum. Questa strategia può essere adottata anche prima che gli algoritmi post-quantum siano completamente standardizzati, offrendo un livello di protezione aggiuntivo \cite{enisa-pqc}. Il secondo approccio prevede il rafforzamento dei sistemi di crittografia attualmente in uso, aumentando la complessità degli schemi basati su chiave simmetrica, che risultano meno suscettibili agli attacchi dei computer quantistici. Questa tecnica di mitigazione rappresenta una soluzione praticabile nel breve termine.

La continuità del servizio è un aspetto critico durante il processo di migrazione verso la crittografia post-quantum. I sistemi ibridi, che applicano in serie tecnologie diverse, non solo aumentano la sicurezza dei sistemi attuali ma agevolano anche la transizione verso nuovi standard. La loro implementazione potrebbe infatti favorire il processo di standardizzazione e l'adozione diffusa dei sistemi PQC, offrendo una piattaforma di prova per valutare la robustezza degli algoritmi post-quantum in ambienti reali.

In generale, l'applicazione di due schemi crittografici in maniera combinata risulta più sicura rispetto all'uso indipendente di ciascuno schema. Questo principio rende i sistemi ibridi una valida opzione per il futuro, poiché aumentano la resilienza contro possibili compromissioni. Tuttavia, una delle principali sfide su cui la ricerca si sta concentrando riguarda lo sviluppo di \textit{combiners} efficienti e sicuri, capaci di integrare diverse tecnologie crittografiche senza compromettere le prestazioni o la sicurezza.

L'adozione di nuovi sistemi crittografici potrebbe non essere sempre fattibile, specialmente per tecnologie meno accessibili e più particolari, come quelle impiegate nei satelliti \cite{nature-pqc}. In aggiunta, la natura non sempre open-source delle ricerche sui computer quantistici comporta che alcuni gruppi di scienziati potrebbero aver ottenuto progressi avanzati in questo campo, di cui non si sarà a conoscenza fino alla pubblicazione dei risultati.

Un ulteriore aspetto critico della migrazione è la necessità di una transizione coordinata. Poiché molti attori (o \textit{parties}) devono utilizzare gli stessi sistemi crittografici per garantire la compatibilità e la sicurezza, il passaggio ai nuovi schemi PQC richiede una migrazione simultanea. Nonostante queste sfide, sono già in corso numerosi test per valutare l'implementazione pratica della crittografia post-quantum. Un esempio significativo è il progetto \textit{Google New Hope}, che utilizza schemi PQC per proteggere parte delle comunicazioni del noto browser Google Chrome, nello specifico verso i siti che supportano questi tipo di tecnologia (principalmente i servizi Google) \cite{wikipedia_newhope}.

L'obiettivo finale di questa transizione verso la crittografia post-quantum rimane quello di bilanciare praticità, sicurezza, prestazioni e costi. La minimizzazione dei costi legati alla rete, alle risorse e al consumo energetico è cruciale per una migrazione efficace e sostenibile. I test di sostituzione degli schemi attuali con protocolli PQC stanno mostrando risultati promettenti, suggerendo che la transizione verso un ambiente crittografico più sicuro e post-quantum potrebbe essere realizzata con successo entro la fine del decennio \cite{NISTthirdReport}.